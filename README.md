# luminex-hackathon_Elite-Fit-4126
Skill-to-Role Mapping ML Project
 ## ğŸš€ Luminex Hackathon Project
Skill-to-Role Mapping with Actionable Career Tips using Machine Learning
## ğŸ“Œ Project Overview

Many learners acquire technical skills but are unaware of the full range of job roles those skills already qualify them for.
They often focus on one popular role and miss adjacent or hidden roles that require almost the same skill set.
This project uses Machine Learning on real job data to:

Map a userâ€™s skills to multiple suitable job roles

Provide actionable skill tips showing what additional skills can unlock new opportunities

The system is simple, explainable, ethical, and hackathon-safe.

## ğŸ¯ Problem Statement

Learners lack data-driven clarity about:

Which job roles they are already eligible for

What small skill upgrades can expand their career options

Most existing career guidance is:

Generic

Opinion-based

Focused on only popular roles

This project solves that using historical job skillâ€“role patterns.

## ğŸ§  Solution Summary

The system:
Takes user skills as text input
Uses a trained ML model to:
Predict Top-N eligible job roles
Compute confidence scores
Analyzes learned model weights to:
Identify important skills for top roles
Recommend missing skills as actionable tips
No aptitude tests.
No personality analysis.
No future prediction.
Just clear, data-driven guidance.

<img width="884" height="556" alt="image" src="https://github.com/user-attachments/assets/1f7b4319-0a6f-4810-971c-9d2786894350" />



##   ğŸ“Š Dataset Description

Source: Real job descriptions dataset (downloaded manually, not via API)

Key columns used:

skills â€“ Required job skills (text)

Role â€“ Job role/title (target variable)

âš ï¸ No synthetic data is used.
âš ï¸ Dataset is preprocessed and stored locally.

## ğŸ”„ Complete ML Workflow (Step-by-Step)
1ï¸âƒ£ Data Loading

Loaded real job dataset

Selected only relevant columns (skills, Role)

Removed missing values

2ï¸âƒ£ Problem Framing

Task type: Multi-class classification

Input: Textual skills

Output: Job role category

3ï¸âƒ£ Data Preparation
Text Cleaning

Lowercasing

Removal of noise & irrelevant tokens

Basic normalization

Feature Engineering (TF-IDF)

Converted skills text into numerical vectors

Used:

ngram_range=(1,2)

min_df=3

max_features=5000

L2 normalization

âš ï¸ TF-IDF was fitted only on training data to prevent data leakage.

4ï¸âƒ£ Trainâ€“Test Split

Used Stratified 80â€“20 split

Reason:

Dataset is imbalanced

Stratification preserves role distribution

Ensures fair evaluation and realistic performance

5ï¸âƒ£ Model Selection

Multiple models were explored conceptually:

Naive Bayes

Linear models

SGD-based classifiers

Final Choice: Logistic Regression

Fast and scalable for large text data

Probabilistic output (predict_proba)

Highly interpretable (feature weights â†’ skill tips)

Industry-trusted baseline for NLP tasks

6ï¸âƒ£ Model Training

Trained on a representative subset (~150k samples) for efficiency

Hyperparameters fixed for stability:

penalty = l2

C = 5

solver = lbfgs
max_iter = 1000
This ensures:
Fast training
No overfitting
Hackathon-time feasibility
7ï¸âƒ£ Model Persistence
Saved artifacts using joblib:
final_logistic_model.joblib
tfidf_vectorizer.joblib
These files are the only dependencies used in deployment.
ğŸŒ Deployment Architecture
Backend Logic
Load trained model and TF-IDF vectorizer
Transform user input
Predict top job roles
Extract important skills using model coefficients
Compare with user skills to suggest missing skills
Frontend (Streamlit)
Skill input box
Predict button with loading animation
Result cards for Top-5 roles
Dedicated skill-tip box
Beginner-friendly guidance for weak inputs


## ğŸ–¥ï¸ How to Run Locally
1ï¸âƒ£ Create Virtual Environment
python -m venv demo
demo\Scripts\activate

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run Application
streamlit run app.py

## ğŸ Conclusion

This project demonstrates a complete, real-world ML pipeline:
Clear problem
Real data
Proper preprocessing
Interpretable modeling
Clean deployment
Immediate user value

